# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ibta9_1oVIrvZZdq1y1Uds2bkuTI6YSA
"""

!pip -q install numpy pandas matplotlib scipy tqdm
!pip -q install qiskit qiskit-aer
!pip -q install cirq

# Commented out IPython magic to ensure Python compatibility.
import os
import random
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
from qiskit import QuantumCircuit
from qiskit_aer import AerSimulator
from qiskit_aer.noise import NoiseModel, depolarizing_error, pauli_error
import cirq

# %matplotlib inline

#Qiskit model
def build_qiskit_noise_model(noise_type="bitflip", p=0.05):
    noise_model = NoiseModel()
    if noise_type == "bitflip":
        err_1q = pauli_error([("X", p), ("I", 1 - p)])
        err_2q = pauli_error([("II", (1 - p)**2),("IX", p * (1 - p)),("XI", p * (1 - p)),("XX", p**2)])
    elif noise_type == "depolarizing":
        err_1q = depolarizing_error(p, 1)
        err_2q = depolarizing_error(p, 2)
    else:
        raise ValueError("noise_type must be 'bitflip' or 'depolarizing'")

    for gate in ["id", "h", "x", "y", "z", "s", "sdg", "t", "tdg"]:
        noise_model.add_all_qubit_quantum_error(err_1q, gate)

    noise_model.add_all_qubit_quantum_error(err_2q, "cx")
    return noise_model

def qiskit_5qubit_circuit():
    qc = QuantumCircuit(5, 5)
    qc.h(0)
    qc.cx(0, 1)
    qc.cx(0, 2)
    qc.cx(0, 3)
    qc.cx(0, 4)
    qc.measure(range(5), range(5))
    return qc


def run_qiskit_multi_p(noise_type="bitflip", p_values=None, shots=2000, seed=42):
    if p_values is None:
        p_values = [0.01, 0.03, 0.05, 0.08, 0.10]
    results = {}
    for p in p_values:
        qc = qiskit_5qubit_circuit()
        noise_model = build_qiskit_noise_model(noise_type=noise_type, p=p)
        sim = AerSimulator(noise_model=noise_model, seed_simulator=seed)
        job = sim.run(qc, shots=shots)
        counts = job.result().get_counts()
        results[p] = counts
    return results

#Syndrome measurement(Ancilla- for logic gates)
def apply_stabilizer_measurement(qc, data_qubits, ancilla, stabilizer):
    qc.reset(ancilla)
    for i, op in enumerate(stabilizer):
        if op == "X":
            qc.h(data_qubits[i])
    for i, op in enumerate(stabilizer):
        if op == "I":
            continue
        elif op == "Z":
            qc.h(ancilla)
            qc.cx(data_qubits[i], ancilla)
            qc.h(ancilla)
        elif op == "X":
            qc.cx(data_qubits[i], ancilla)
        else:
            raise ValueError("Only I/X/Z supported in this stabilizer demo")

    for i, op in enumerate(stabilizer):
        if op == "X":
            qc.h(data_qubits[i])


def qiskit_syndrome_measurement_circuit():
    data = list(range(5))
    anc = list(range(5, 9))   # 4ancillas
    cl = list(range(4))       # 4classical bits

    qc = QuantumCircuit(9, 4)
    stabilizers = ["XZZXI", "IXZZX", "XIXZZ", "ZXIXZ"]

    for k, stab in enumerate(stabilizers):
        apply_stabilizer_measurement(qc, data_qubits=data, ancilla=anc[k], stabilizer=stab)
        qc.measure(anc[k], cl[k])
    return qc

#cirq model
def cirq_5qubit_circuit(noise_type="bitflip", p=0.05):
    qubits = cirq.LineQubit.range(5)
    circuit = cirq.Circuit()
    circuit.append(cirq.H(qubits[0]))
    for i in range(1, 5):
        circuit.append(cirq.CNOT(qubits[0], qubits[i]))
    if noise_type == "bitflip":
        noise_gate = cirq.bit_flip(p)
    elif noise_type == "depolarizing":
        noise_gate = cirq.depolarize(p)
    else:
        raise ValueError("noise_type must be 'bitflip' or 'depolarizing'")
    circuit.append(noise_gate.on_each(*qubits))
    circuit.append(cirq.measure(*qubits, key="m"))
    return qubits, circuit


def run_cirq_multi_p(noise_type="bitflip", p_values=None, reps=2000, seed=42):
    if p_values is None:
        p_values = [0.01, 0.03, 0.05, 0.08, 0.10]
    results = {}
    sim = cirq.Simulator(seed=seed)
    for p in p_values:
        _, circuit = cirq_5qubit_circuit(noise_type=noise_type, p=p)
        result = sim.run(circuit, repetitions=reps)
        hist = result.histogram(key="m")
        results[p] = hist
    return results

#simulation for noisy bits
def run_simulation_both_noises(p_values=None, shots=2000, reps=2000, seed=42):
    if p_values is None:
        p_values = [0.01, 0.03, 0.05, 0.08, 0.10]
    results = {"qiskit": {}, "cirq": {}}
    for noise_type in ["bitflip", "depolarizing"]:
        results["qiskit"][noise_type] = run_qiskit_multi_p(noise_type, p_values, shots, seed)
        results["cirq"][noise_type] = run_cirq_multi_p(noise_type, p_values, reps, seed)

    return results

def run_syndrome_measurement_qiskit(noise_type="bitflip", p=0.05, shots=2000, seed=42):
    qc = qiskit_syndrome_measurement_circuit()
    noise_model = build_qiskit_noise_model(noise_type=noise_type, p=p)
    sim = AerSimulator(noise_model=noise_model, seed_simulator=seed)
    job = sim.run(qc, shots=shots)
    result = job.result()
    syndrome_counts = result.get_counts()
    return qc, syndrome_counts

#after simulation storing data to csv
def qiskit_counts_to_df(qiskit_results, noise_type):
    rows = []
    for p, counts in qiskit_results.items():
        for outcome, count in counts.items():
            rows.append({"backend":"qiskit","noise":noise_type,"p":float(p),"outcome":outcome,"count":int(count)})
    return pd.DataFrame(rows)

def cirq_hist_to_df(cirq_results, noise_type, n_qubits=5):
    rows = []
    for p, hist in cirq_results.items():
        for outcome_int, count in hist.items():
            outcome = format(outcome_int, f"0{n_qubits}b")
            rows.append({"backend":"cirq","noise":noise_type,"p":float(p),"outcome":outcome,"count":int(count)})
    return pd.DataFrame(rows)

def save_simulation_results_both_noises(results, merged_all_csv="simulation_results_ALL.csv"):
    merged_dfs = []
    df_q_bf = qiskit_counts_to_df(results["qiskit"]["bitflip"], "bitflip")
    df_q_dp = qiskit_counts_to_df(results["qiskit"]["depolarizing"], "depolarizing")
    df_c_bf = cirq_hist_to_df(results["cirq"]["bitflip"], "bitflip")
    df_c_dp = cirq_hist_to_df(results["cirq"]["depolarizing"], "depolarizing")
    df_q_bf.to_csv("qiskit_bitflip_results.csv", index=False)
    df_q_dp.to_csv("qiskit_depolarizing_results.csv", index=False)
    df_c_bf.to_csv("cirq_bitflip_results.csv", index=False)
    df_c_dp.to_csv("cirq_depolarizing_results.csv", index=False)
    merged_all = pd.concat([df_q_bf, df_q_dp, df_c_bf, df_c_dp], ignore_index=True)
    merged_all.to_csv(merged_all_csv, index=False)
    return merged_all

#stablizing the noisy bits using pauli and rl
STABILIZERS = ["XZZXI","IXZZX","XIXZZ","ZXIXZ"]
PAULI_MULT = {
    ("I","I"):"I", ("I","X"):"X", ("I","Y"):"Y", ("I","Z"):"Z",
    ("X","I"):"X", ("X","X"):"I", ("X","Y"):"Z", ("X","Z"):"Y",
    ("Y","I"):"Y", ("Y","X"):"Z", ("Y","Y"):"I", ("Y","Z"):"X",
    ("Z","I"):"Z", ("Z","X"):"Y", ("Z","Y"):"X", ("Z","Z"):"I"
}

def anticommutes(p, q):
    if p=="I" or q=="I": return False
    if p==q: return False
    return True

def syndrome_for_error(error_paulis):
    syn=[]
    for stab in STABILIZERS:
        bit=0
        for i in range(5):
            if anticommutes(error_paulis[i], stab[i]):
                bit ^= 1
        syn.append(bit)
    return tuple(syn)

def noise_bitflip(p):
    return ["X" if random.random()<p else "I" for _ in range(5)]

def noise_depolarizing(p):
    out=[]
    for _ in range(5):
        r=random.random()
        if r < 1-p: out.append("I")
        else:
            rr=random.random()
            out.append("X" if rr<1/3 else ("Y" if rr<2/3 else "Z"))
    return out

def apply_pauli_correction(error, action):
    return [PAULI_MULT[(a,e)] for a,e in zip(action, error)]

def is_identity(error):
    return all(e=="I" for e in error)

def action_space_20():
    actions=[]
    for q in range(5):
        for p in ["I","X","Y","Z"]:
            act=["I"]*5
            act[q]=p
            actions.append(tuple(act))
    return actions

from collections import defaultdict
#Q- learning alg
class QLearningAgent:
    def __init__(self, actions, alpha=0.2, gamma=0.9, epsilon=0.3, epsilon_min=0.05, epsilon_decay=0.999):
        self.actions=actions
        self.alpha=alpha
        self.gamma=gamma
        self.epsilon=epsilon
        self.epsilon_min=epsilon_min
        self.epsilon_decay=epsilon_decay
        self.Q=defaultdict(float)

    def choose_action(self, state):
        if random.random() < self.epsilon:
            return random.choice(self.actions)
        qvals=[self.Q[(state,a)] for a in self.actions]
        return self.actions[int(np.argmax(qvals))]

    def update(self, s,a,r,s2):
        best_next=max(self.Q[(s2,a2)] for a2 in self.actions)
        self.Q[(s,a)] += self.alpha*(r + self.gamma*best_next - self.Q[(s,a)])

    def decay(self):
        self.epsilon=max(self.epsilon_min, self.epsilon*self.epsilon_decay)

def train_qlearning_agent(noise_type="bitflip", p=0.05, episodes=50000, seed=42):
    random.seed(seed); np.random.seed(seed)
    agent = QLearningAgent(actions=action_space_20())
    rewards=[]

    for _ in tqdm(range(episodes), desc=f"Training ({noise_type}, p={p})"):
        error = noise_bitflip(p) if noise_type=="bitflip" else noise_depolarizing(p)
        s = syndrome_for_error(error)
        a = agent.choose_action(s)
        corrected = apply_pauli_correction(error, a)
        success=int(is_identity(corrected))
        r=1 if success else -1
        s2 = syndrome_for_error(corrected)
        agent.update(s,a,r,s2)
        agent.decay()
        rewards.append(r)

    return agent, rewards

def greedy_policy_from_agent(agent):
    def policy(state):
        qvals=[agent.Q[(state,a)] for a in agent.actions]
        return agent.actions[int(np.argmax(qvals))]
    return policy

def plot_reward_curve(reward_history, window=500):
    if reward_history is None or len(reward_history)==0:
        print("reward_history empty")
        return
    reward_history=np.array(reward_history, dtype=float)
    if len(reward_history)<window:
        window=max(10, len(reward_history)//5)
    smooth=np.convolve(reward_history, np.ones(window)/window, mode="valid")
    plt.figure(figsize=(10,4))
    plt.plot(smooth)
    plt.xlabel("Episode")
    plt.ylabel("Smoothed Reward")
    plt.grid(True)
    plt.show()

def evaluate_logical_error_rates(policy, noise_type="bitflip", p=0.05, trials=20000, seed=123):
    random.seed(seed); np.random.seed(seed)
    before_fail=0; after_fail=0

    for _ in tqdm(range(trials), desc=f"Testing ({noise_type}, p={p})"):
        error = noise_bitflip(p) if noise_type=="bitflip" else noise_depolarizing(p)

        if not is_identity(error):
            before_fail += 1

        s = syndrome_for_error(error)
        a = policy(s)
        corrected = apply_pauli_correction(error, a)
        if not is_identity(corrected):
            after_fail += 1

    return before_fail/trials, after_fail/trials

def combine_errors(e1, e2):
    return [PAULI_MULT[(a,b)] for a,b in zip(e1,e2)]

def sample_noise_error(noise_type, p):
    return noise_bitflip(p) if noise_type=="bitflip" else noise_depolarizing(p)

def simulate_lifetime_episode(policy, noise_type="bitflip", p=0.05, T=50, seed=None):
    if seed is not None:
        random.seed(seed); np.random.seed(seed)

    current_error=["I"]*5
    for t in range(1, T+1):
        current_error = combine_errors(current_error, sample_noise_error(noise_type,p))
        s = syndrome_for_error(current_error)
        a = policy(s)
        current_error = apply_pauli_correction(current_error, a)

        if not is_identity(current_error):
            return t
    return T

def compute_survival_curve(policy, noise_type="bitflip", p=0.05, T=50, n_runs=500, seed=123):
    lifetimes=[]
    for i in tqdm(range(n_runs), desc=f"Survival ({noise_type}, p={p})"):
        lifetimes.append(simulate_lifetime_episode(policy, noise_type, p, T, seed+i))
    lifetimes=np.array(lifetimes)

    survival=[]
    for t in range(1, T+1):
        survival.append(np.mean(lifetimes>=t))
    return np.array(survival), lifetimes

def plot_survival_curve(survival, title="Survival Probability"):
    plt.figure(figsize=(10,4))
    plt.plot(range(1,len(survival)+1), survival)
    plt.xlabel("Time step")
    plt.ylabel("Survival probability")
    plt.grid(True)
    plt.title(title)
    plt.show()

# before rl execution
def baseline_policy(state):
    return ("I","I","I","I","I")

def evaluate_error_rate_vs_p(trained_policy, noise_type="bitflip", p_values=None, T=50, n_runs=300):
    if p_values is None:
        p_values=[0.01,0.03,0.05,0.08,0.10]
    rows=[]
    for p in p_values:
        base_surv, base_lt = compute_survival_curve(baseline_policy, noise_type, p, T, n_runs, seed=1000)
        rl_surv, rl_lt = compute_survival_curve(trained_policy, noise_type, p, T, n_runs, seed=2000)
        rows.append({
            "noise": noise_type,
            "p": p,
            "T": T,
            "runs": n_runs,
            "baseline_fail_prob": 1-base_surv[-1],
            "rl_fail_prob": 1-rl_surv[-1],
            "baseline_avg_lifetime": float(np.mean(base_lt)),
            "rl_avg_lifetime": float(np.mean(rl_lt))
        })

    return pd.DataFrame(rows)
def plot_error_rate_vs_p(df, title="Error Rate vs p"):
    plt.figure(figsize=(10,4))
    plt.plot(df["p"], df["baseline_fail_prob"], marker="o")
    plt.plot(df["p"], df["rl_fail_prob"], marker="o")
    plt.xlabel("Physical error probability p")
    plt.ylabel("Logical failure probability")
    plt.grid(True)
    plt.title(title)
    plt.legend(["Baseline", "RL"])
    plt.show()

#avg of befor rl and after rl
from scipy import stats

def mean_ci_95(values):
    values = np.array(values, dtype=float)
    n = len(values)
    mean = float(np.mean(values))
    if n < 2:
        return mean, mean, mean
    sem = stats.sem(values)  # standard error of mean
    h = sem * stats.t.ppf(0.975, df=n-1)  # 95% CI
    return mean, mean - h, mean + h

def evaluate_with_ci(
    agent,
    noise_type="bitflip",
    p=0.05,
    trials=5000,
    T=50,
    lifetime_runs=300,
    repeats=10
):

    policy = greedy_policy_from_agent(agent)
    before_rates = []
    after_rates  = []
    base_lifetime_means = []
    rl_lifetime_means   = []

    for k in range(repeats):
        seed_test = 100 + 50*k
        # error rates
        br, ar = evaluate_logical_error_rates(
            policy=policy,
            noise_type=noise_type,
            p=p,
            trials=trials,
            seed=seed_test
        )
        before_rates.append(br)
        after_rates.append(ar)
        _, base_lt = compute_survival_curve(
            policy=baseline_policy,
            noise_type=noise_type,
            p=p,
            T=T,
            n_runs=lifetime_runs,
            seed=2000 + 50*k
        )
        _, rl_lt = compute_survival_curve(
            policy=policy,
            noise_type=noise_type,
            p=p,
            T=T,
            n_runs=lifetime_runs,
            seed=3000 + 50*k
        )
        base_lifetime_means.append(np.mean(base_lt))
        rl_lifetime_means.append(np.mean(rl_lt))

    before_mean, before_low, before_high = mean_ci_95(before_rates)
    after_mean, after_low, after_high = mean_ci_95(after_rates)

    base_lt_mean, base_lt_low, base_lt_high = mean_ci_95(base_lifetime_means)
    rl_lt_mean, rl_lt_low, rl_lt_high = mean_ci_95(rl_lifetime_means)

    summary = pd.DataFrame([{
        "noise": noise_type,
        "p": p,
        "trials_each_repeat": trials,
        "repeats": repeats,

        "before_mean": before_mean,
        "before_ci_low": before_low,
        "before_ci_high": before_high,

        "after_mean": after_mean,
        "after_ci_low": after_low,
        "after_ci_high": after_high,

        "baseline_lifetime_mean": base_lt_mean,
        "baseline_lifetime_ci_low": base_lt_low,
        "baseline_lifetime_ci_high": base_lt_high,

        "rl_lifetime_mean": rl_lt_mean,
        "rl_lifetime_ci_low": rl_lt_low,
        "rl_lifetime_ci_high": rl_lt_high,
    }])

    return summary

# ============================================================
# SECTION 14: CI TABLE FOR MULTIPLE p VALUES (BOTH NOISES)
# ============================================================

def ci_table_over_p(
    agent,
    p_values=None,
    trials=5000,
    T=50,
    lifetime_runs=200,
    repeats=6
):
    if p_values is None:
        p_values = [0.01, 0.03, 0.05, 0.08, 0.10]

    rows = []
    for noise_type in ["bitflip", "depolarizing"]:
        for p in p_values:
            df_ci = evaluate_with_ci(
                agent=agent,
                noise_type=noise_type,
                p=p,
                trials=trials,
                T=T,
                lifetime_runs=lifetime_runs,
                repeats=repeats
            )
            rows.append(df_ci.iloc[0].to_dict())

    return pd.DataFrame(rows)

#plot of baseline vs rl
def plot_error_rate_vs_p_both_noises(agent, p_values=None, T=50, n_runs=200):
    if p_values is None:
        p_values = [0.01, 0.03, 0.05, 0.08, 0.10]
    policy = greedy_policy_from_agent(agent)
    df_bf = evaluate_error_rate_vs_p(policy, noise_type="bitflip", p_values=p_values, T=T, n_runs=n_runs)
    df_dp = evaluate_error_rate_vs_p(policy, noise_type="depolarizing", p_values=p_values, T=T, n_runs=n_runs)
    plt.figure(figsize=(10, 4))
    # baseline
    plt.plot(df_bf["p"], df_bf["baseline_fail_prob"], marker="o")
    plt.plot(df_dp["p"], df_dp["baseline_fail_prob"], marker="o")
    # RL
    plt.plot(df_bf["p"], df_bf["rl_fail_prob"], marker="o")
    plt.plot(df_dp["p"], df_dp["rl_fail_prob"], marker="o")
    plt.xlabel("Physical error probability p")
    plt.ylabel("Logical failure probability (after T steps)")
    plt.grid(True)
    plt.title("Baseline vs RL: Error Rate vs p (Bitflip & Depolarizing)")
    plt.legend(["Baseline - Bitflip", "Baseline - Depolarizing","RL - Bitflip","RL - Depolarizing"  ])
    plt.show()
    return df_bf, df_dp

#survive time of bit and depolarizing
def plot_survival_curve_both_noises(agent, p=0.05, T=50, n_runs=300):
    policy = greedy_policy_from_agent(agent)
    surv_bf, _ = compute_survival_curve(policy, noise_type="bitflip", p=p, T=T, n_runs=n_runs, seed=111)
    surv_dp, _ = compute_survival_curve(policy, noise_type="depolarizing", p=p, T=T, n_runs=n_runs, seed=222)
    plt.figure(figsize=(10, 4))
    plt.plot(range(1, T+1), surv_bf)
    plt.plot(range(1, T+1), surv_dp)
    plt.xlabel("Time step")
    plt.ylabel("Survival probability")
    plt.grid(True)
    plt.title(f"RL Survival Curves (p={p})")
    plt.legend(["Bitflip", "Depolarizing"])
    plt.show()
    return surv_bf, surv_dp

#dataset generation for rl
def generate_rl_dataset_csv(agent, out_csv="rl_training_dataset.csv", noise_type="bitflip", p=0.05, n_samples=30000, seed=999):
    random.seed(seed); np.random.seed(seed)
    rows=[]
    actions=agent.actions
    for i in tqdm(range(n_samples), desc="RL dataset gen"):
        error = sample_noise_error(noise_type, p)
        s = syndrome_for_error(error)
        qvals=[agent.Q[(s,a)] for a in actions]
        a = actions[int(np.argmax(qvals))]
        corrected = apply_pauli_correction(error, a)
        success=int(is_identity(corrected))
        r=1 if success else -1
        s2 = syndrome_for_error(corrected)
        rows.append({
            "sample_id": i,
            "noise": noise_type,
            "p": p,
            "state_syndrome": "".join(map(str,s)),
            "true_error": "".join(error),
            "action": "".join(a),
            "corrected_error": "".join(corrected),
            "next_syndrome": "".join(map(str,s2)),
            "reward": r,
            "success": success
        })
    df=pd.DataFrame(rows)
    df.to_csv(out_csv, index=False)
    return df

def generate_rl_dataset_both_noises(
    p=0.05,
    episodes=50000,
    n_samples=20000,
    seed=42
):
    saved_files = []
    for noise_type in ["bitflip", "depolarizing"]:
        # Train RL agent for each noise
        agent, reward_history = train_qlearning_agent(
            noise_type=noise_type,
            p=p,
            episodes=episodes,
            seed=seed
        )
        out_csv = f"rl_training_dataset_{noise_type}.csv"
        df_rl = generate_rl_dataset_csv(
            agent=agent,
            out_csv=out_csv,
            noise_type=noise_type,
            p=p,
            n_samples=n_samples,
            seed=seed + 999
        )
        print(f" Saved: {out_csv}  | rows: {len(df_rl)}")
        saved_files.append(out_csv)
    return saved_files

PLOT_W, PLOT_H = 7, 3   # plot reduced size
results = run_simulation_both_noises(
    p_values=[0.01, 0.03, 0.05, 0.08, 0.10],
    shots=2000,
    reps=2000,
    seed=42
)
merged_all = save_simulation_results_both_noises(results)
print("Simulation CSV saved (Qiskit + Cirq)")
#rl train
agent, reward_history = train_qlearning_agent(
    noise_type="bitflip",
    p=0.05,
    episodes=50000,
    seed=42
)
plt.figure(figsize=(PLOT_W, PLOT_H))
plot_reward_curve(reward_history, window=1000)

policy = greedy_policy_from_agent(agent)
before_rate, after_rate = evaluate_logical_error_rates(
    policy=policy,
    noise_type="bitflip",
    p=0.05,
    trials=10000,
    seed=123
)

print(f" Logical Error Rate BEFORE correction: {before_rate:.4f}")
print(f" Logical Error Rate AFTER  RL correction: {after_rate:.4f}")

#survive time for bitflip and depolarizing
survival, lifetimes = compute_survival_curve(
    policy=policy,
    noise_type="bitflip",
    p=0.05,
    T=50,
    n_runs=300,
    seed=123
)

plt.figure(figsize=(PLOT_W, PLOT_H))
plot_survival_curve(survival, title="RL Survival Curve (Bitflip, p=0.05)")

df_p = evaluate_error_rate_vs_p(
    trained_policy=policy,
    noise_type="bitflip",
    p_values=[0.01, 0.03, 0.05, 0.08, 0.10],
    T=50,
    n_runs=200
)

plt.figure(figsize=(PLOT_W, PLOT_H))
plot_error_rate_vs_p(df_p, title="Bitflip: Error Rate vs p")

# rl dataset savinng
df_rl = generate_rl_dataset_csv(
    agent=agent,
    out_csv="rl_training_dataset.csv",
    noise_type="bitflip",
    p=0.05,
    n_samples=20000,
    seed=999
)
print(" RL dataset CSV saved: rl_training_dataset.csv")

saved_csvs = generate_rl_dataset_both_noises(
    p=0.05,
    episodes=50000,
    n_samples=20000,
    seed=42
)
print("All RL CSV files:", saved_csvs)



#plots
df_ci = ci_table_over_p(
    agent=agent,
    p_values=[0.01, 0.03, 0.05, 0.08, 0.10],
    trials=3000,
    T=50,
    lifetime_runs=150,
    repeats=5
)
print(" Confidence Interval Results Table:")
display(df_ci)

df_bf, df_dp = plot_error_rate_vs_p_both_noises(
    agent=agent,
    p_values=[0.01, 0.03, 0.05, 0.08, 0.10],
    T=50,
    n_runs=150
)

surv_bf, surv_dp = plot_survival_curve_both_noises(
    agent=agent,
    p=0.05,
    T=50,
    n_runs=200
)

print(" Combined IEEE plots generated")

# Save simulation merged output
merged_all.to_csv("simulation_results_ALL.csv", index=False)
# Save RL dataset
df_rl.to_csv("rl_training_dataset.csv", index=False)
# Save CI table
df_ci.to_csv("ci_results_table.csv", index=False)

!zip -r overall_data.zip *.csv
from google.colab import files
files.download("overall_data.zip")

from google.colab import files

files.download("rl_training_dataset_bitflip.csv")
files.download("rl_training_dataset_depolarizing.csv")